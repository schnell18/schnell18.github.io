<div id="pfa" class="pf w0 h0" data-page-no="a"><div class="pc pca w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="data:image/png;base64,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"/><div class="t m0 x6 h3 y6d ff2 fs2 fc0 sc0 ls0 ws0">3.4<span class="_ _14"> </span>SensiBoost<span class="_ _8"> </span>and<span class="_ _a"> </span>KurtBoost</div><div class="t m5 x6 h5 y1f9 ff1 fs2 fc0 sc0 ls0 ws0">This<span class="_"> </span>section<span class="_ _8"> </span>describes<span class="_ _8"> </span>SensiBoost<span class="_"> </span>and<span class="_ _8"> </span>K<span class="_ _b"></span>urtBoost,<span class="_"> </span>the<span class="_ _8"> </span>two<span class="_ _8"> </span>methods<span class="_"> </span>le<span class="_ _4"></span>veraging<span class="_"> </span>acti<span class="_ _4"></span>vation<span class="_ _8"> </span>sensiti<span class="_ _4"></span>vity<span class="_"> </span>and<span class="_"> </span>K<span class="_ _b"></span>urtosis<span class="_"> </span>metrics</div><div class="t md x6 h5 y1fa ff1 fs2 fc0 sc0 ls0 ws0">to<span class="_"> </span>enhance<span class="_"> </span>quantization<span class="_"> </span>accuracy<span class="_"> </span>with<span class="_"> </span>a<span class="_"> </span>minimal<span class="_"> </span>increment<span class="_"> </span>in<span class="_"> </span>the<span class="_"> </span>bit<span class="_"> </span>budget.<span class="_ _c"> </span>The<span class="_"> </span>ne<span class="_ _b"></span>w<span class="_"> </span>approaches<span class="_"> </span>are<span class="_"> </span>implemented<span class="_"> </span>by</div><div class="t m0 x6 h5 y1fb ff1 fs2 fc0 sc0 ls0 ws0">identifying<span class="_"> </span>the<span class="_"> </span>sensitiv<span class="_ _4"></span>e<span class="_"> </span>layers<span class="_"> </span>using<span class="_"> </span>the<span class="_"> </span>outlier<span class="_"> </span>detection<span class="_"> </span>algorithm<span class="_"> </span>explained<span class="_"> </span>in<span class="_"> </span>the<span class="_"> </span>previous<span class="_"> </span>Section<span class="_"> </span>3.3.</div><div class="t m0 x6 h5 y1fc ff1 fs2 fc0 sc0 ls0 ws0">The<span class="_"> </span>key<span class="_"> </span>steps<span class="_"> </span>of<span class="_"> </span>the<span class="_"> </span>SensiBoost<span class="_"> </span>and<span class="_"> </span>K<span class="_ _4"></span>urBoost<span class="_"> </span>are<span class="_"> </span>as<span class="_"> </span>follows:</div><div class="t m0 xfb h5 y1fd ff1 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _3"> </span>Load<span class="_"> </span>the<span class="_"> </span>pre-calculated<span class="_"> </span>sensitivity<span class="_"> </span>scores<span class="_"> </span>or<span class="_"> </span>K<span class="_ _4"></span>urtosis<span class="_"> </span>metrics<span class="_"> </span>for<span class="_"> </span>the<span class="_"> </span>model<span class="_"> </span>being<span class="_"> </span>quantized.</div><div class="t m0 xfb h6 y1fe ff1 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _3"> </span>Identify<span class="_"> </span>layers<span class="_"> </span>for<span class="_"> </span>additional<span class="_"> </span>allocation<span class="_"> </span>using<span class="_"> </span>the<span class="_"> </span>outlier<span class="_"> </span>detection<span class="_"> </span>algorithm<span class="_"> </span>according<span class="_"> </span>to<span class="_"> </span>the<span class="_"> </span>top-<span class="ffb">m<span class="_ _a"> </span></span>setting.</div><div class="t m0 xfb h5 y1ff ff1 fs2 fc0 sc0 ls0 ws0">3.</div><div class="t m5 x5 h5 y1ff ff1 fs2 fc0 sc0 ls0 ws0">Allocate<span class="_"> </span>normal<span class="_"> </span>b<span class="_ _b"></span>udget<span class="_"> </span>to<span class="_"> </span>non-sensiti<span class="_ _b"></span>ve<span class="_"> </span>layers<span class="_"> </span>and<span class="_"> </span>assign<span class="_ _8"> </span>additional<span class="_"> </span>b<span class="_ _b"></span>udget<span class="_"> </span>to<span class="_"> </span>sensiti<span class="_ _b"></span>ve<span class="_"> </span>layers<span class="_"> </span>according<span class="_"> </span>to<span class="_ _8"> </span>the</div><div class="t m0 x5 h5 y200 ff1 fs2 fc0 sc0 ls0 ws0">boost<span class="_"> </span>stop<span class="_"> </span>setting.</div><div class="t m0 xfb h5 y201 ff1 fs2 fc0 sc0 ls0 ws0">4.<span class="_ _f"> </span>Apply<span class="_"> </span>quantization<span class="_"> </span>using<span class="_"> </span>the<span class="_"> </span>underlying<span class="_"> </span>quantization<span class="_"> </span>method.</div><div class="t m0 x33 h5 y202 ff1 fs2 fc0 sc0 ls0 ws0">T<span class="_ _1"></span>able<span class="_"> </span>1:<span class="_ _d"> </span>HQQ<span class="_"> </span>bit<span class="_"> </span>b<span class="_ _b"></span>udgets</div><div class="t m0 x1d h12 y203 ff2 fs9 fc0 sc0 ls0 ws0">stop<span class="_ _22"> </span>budget<span class="_ _22"> </span><span class="ffb">b</span></div><div class="t m0 x1e h13 y204 fff fsa fc0 sc0 ls0 ws0">1</div><div class="t m0 xbe h12 y203 ffb fs9 fc0 sc0 ls0 ws0">g</div><div class="t m0 xc1 h13 y204 fff fsa fc0 sc0 ls0 ws0">1</div><div class="t m0 x116 h12 y203 ffb fs9 fc0 sc0 ls0 ws0">b</div><div class="t m0 x98 h13 y204 fff fsa fc0 sc0 ls0 ws0">2</div><div class="t m0 x72 h12 y203 ffb fs9 fc0 sc0 ls0 ws0">g</div><div class="t m0 x14b h13 y204 fff fsa fc0 sc0 ls0 ws0">2</div><div class="t m0 x3d h12 y203 ff2 fs9 fc0 sc0 ls0 ws0">stop<span class="_ _22"> </span>budget<span class="_ _22"> </span><span class="ffb">b</span></div><div class="t m0 x14c h13 y204 fff fsa fc0 sc0 ls0 ws0">1</div><div class="t m0 x14d h12 y203 ffb fs9 fc0 sc0 ls0 ws0">g</div><div class="t m0 xe8 h13 y204 fff fsa fc0 sc0 ls0 ws0">1</div><div class="t m0 xe6 h12 y203 ffb fs9 fc0 sc0 ls0 ws0">b</div><div class="t m0 x14e h13 y204 fff fsa fc0 sc0 ls0 ws0">2</div><div class="t m0 x14f h12 y203 ffb fs9 fc0 sc0 ls0 ws0">g</div><div class="t m0 xfc h13 y204 fff fsa fc0 sc0 ls0 ws0">2</div><div class="t m0 x150 h14 y205 ff1 fs9 fc0 sc0 ls0 ws0">0<span class="_ _23"> </span>2.13<span class="_ _24"> </span>2<span class="_ _25"> </span>128<span class="_ _25"> </span>8<span class="_ _25"> </span>128<span class="_ _26"> </span>+1<span class="_ _23"> </span>2.25<span class="_ _24"> </span>2<span class="_ _27"> </span>64<span class="_ _27"> </span>8<span class="_ _25"> </span>128</div><div class="t m0 x139 h14 y206 ff1 fs9 fc0 sc0 ls0 ws0">+2<span class="_ _23"> </span>2.51<span class="_ _24"> </span>2<span class="_ _27"> </span>32<span class="_ _27"> </span>8<span class="_ _25"> </span>128<span class="_ _26"> </span>+3<span class="_ _23"> </span>3.13<span class="_ _24"> </span>3<span class="_ _25"> </span>128<span class="_ _25"> </span>8<span class="_ _25"> </span>128</div><div class="t m0 x139 h14 y207 ff1 fs9 fc0 sc0 ls0 ws0">+4<span class="_ _23"> </span>3.25<span class="_ _24"> </span>3<span class="_ _27"> </span>64<span class="_ _27"> </span>8<span class="_ _25"> </span>128<span class="_ _26"> </span>+5<span class="_ _23"> </span>3.51<span class="_ _24"> </span>3<span class="_ _27"> </span>32<span class="_ _27"> </span>8<span class="_ _25"> </span>128</div><div class="t m0 x139 h14 y208 ff1 fs9 fc0 sc0 ls0 ws0">+6<span class="_ _23"> </span>4.13<span class="_ _24"> </span>4<span class="_ _25"> </span>128<span class="_ _25"> </span>8<span class="_ _25"> </span>128<span class="_ _26"> </span>+7<span class="_ _23"> </span>4.25<span class="_ _24"> </span>4<span class="_ _27"> </span>64<span class="_ _27"> </span>8<span class="_ _25"> </span>128</div><div class="t m0 x139 h14 y209 ff1 fs9 fc0 sc0 ls0 ws0">+8<span class="_ _23"> </span>4.51<span class="_ _24"> </span>4<span class="_ _27"> </span>32<span class="_ _27"> </span>8<span class="_ _25"> </span>128<span class="_ _26"> </span>+9<span class="_ _23"> </span>8.13<span class="_ _24"> </span>8<span class="_ _25"> </span>128<span class="_ _25"> </span>8<span class="_ _25"> </span>128</div><div class="t m0 x151 h14 y20a ff1 fs9 fc0 sc0 ls0 ws0">+10<span class="_ _23"> </span>8.25<span class="_ _24"> </span>8<span class="_ _27"> </span>64<span class="_ _27"> </span>8<span class="_ _25"> </span>128<span class="_ _25"> </span>+11<span class="_ _23"> </span>8.51<span class="_ _24"> </span>8<span class="_ _27"> </span>32<span class="_ _27"> </span>8<span class="_ _25"> </span>128</div><div class="t m11 x6 h5 y20b ff1 fs2 fc0 sc0 ls0 ws0">T<span class="_ _1"></span>o<span class="_"> </span>apply<span class="_"> </span>additional<span class="_"> </span>memory<span class="_"> </span>allocation,<span class="_"> </span>the<span class="_"> </span>amount<span class="_"> </span>of<span class="_"> </span>surplus<span class="_"> </span>b<span class="_ _4"></span>udget<span class="_"> </span>for<span class="_"> </span>the<span class="_"> </span>sensiti<span class="_ _b"></span>ve<span class="_"> </span>layers<span class="_ _8"> </span>can<span class="_"> </span>be<span class="_"> </span>speciﬁed<span class="_"> </span>by<span class="_"> </span>the</div><div class="t m1f x6 h3 y20c ff1 fs2 fc0 sc0 ls0 ws0">number<span class="_"> </span>of<span class="_"> </span><span class="ff2">boost<span class="_ _8"> </span>stops</span>.<span class="_ _d"> </span>When<span class="_"> </span>boost<span class="_"> </span>stops<span class="_"> </span>go<span class="_"> </span>beyond<span class="_"> </span>the<span class="_"> </span>maximum<span class="_"> </span>bit<span class="_"> </span>b<span class="_ _4"></span>udget<span class="_"> </span>of<span class="_"> </span>the<span class="_"> </span>underlying<span class="_"> </span>quantization<span class="_"> </span>method,</div><div class="t m19 x6 h5 y20d ff1 fs2 fc0 sc0 ls0 ws0">the<span class="_"> </span>maximum<span class="_"> </span>bit<span class="_"> </span>budget<span class="_"> </span>tak<span class="_ _4"></span>es<span class="_"> </span>effect.<span class="_ _c"> </span>T<span class="_ _4"></span>able<span class="_"> </span>1<span class="_"> </span>presents<span class="_"> </span>the<span class="_"> </span>12-stop<span class="_"> </span>bit<span class="_"> </span>b<span class="_ _4"></span>udgets<span class="_"> </span>on<span class="_"> </span>top<span class="_"> </span>of<span class="_"> </span>HQQ.<span class="_"> </span>For<span class="_"> </span>instance,<span class="_"> </span>when<span class="_"> </span>the</div><div class="t m22 x6 h5 y20e ff1 fs2 fc0 sc0 ls0 ws0">base<span class="_"> </span>bit<span class="_"> </span>budget<span class="_"> </span>is<span class="_"> </span>4.13,<span class="_"> </span>a<span class="_"> </span>setting<span class="_ _8"> </span>of<span class="_"> </span>2-stop<span class="_"> </span>will<span class="_"> </span>quantize<span class="_"> </span>the<span class="_"> </span>sensiti<span class="_ _b"></span>ve<span class="_"> </span>layers<span class="_"> </span>with<span class="_"> </span>a<span class="_"> </span>bit<span class="_"> </span>b<span class="_ _4"></span>udget<span class="_"> </span>of<span class="_"> </span>4.51.<span class="_ _c"> </span>Howe<span class="_ _b"></span>ver<span class="_ _4"></span>,<span class="_"> </span>when</div><div class="t m0 x6 h5 y20f ff1 fs2 fc0 sc0 ls0 ws0">the<span class="_"> </span>base<span class="_"> </span>bit<span class="_"> </span>budget<span class="_"> </span>is<span class="_"> </span>8.25,<span class="_"> </span>a<span class="_"> </span>2-stop<span class="_"> </span>increment<span class="_"> </span>request<span class="_"> </span>only<span class="_"> </span>results<span class="_"> </span>in<span class="_"> </span>1<span class="_"> </span>stop,<span class="_"> </span>i.e.,<span class="_"> </span>a<span class="_"> </span>bit<span class="_"> </span>b<span class="_ _4"></span>udget<span class="_"> </span>of<span class="_"> </span>8.51.</div><div class="t m5 x6 h5 y210 ff1 fs2 fc0 sc0 ls0 ws0">The<span class="_"> </span>number<span class="_"> </span>of<span class="_"> </span>layers<span class="_"> </span>targeted<span class="_"> </span>for<span class="_"> </span>extra<span class="_"> </span>allocation<span class="_"> </span>can<span class="_"> </span>be<span class="_"> </span>restricted<span class="_"> </span>based<span class="_"> </span>on<span class="_"> </span>the<span class="_"> </span>descending<span class="_"> </span>rank<span class="_"> </span>of<span class="_"> </span>sensiti<span class="_ _4"></span>vity<span class="_"> </span>scores<span class="_"> </span>or</div><div class="t m5 x6 h5 y211 ff1 fs2 fc0 sc0 ls0 ws0">Kurtosis<span class="_"> </span>metrics.<span class="_ _c"> </span>The<span class="_"> </span>resulting<span class="_"> </span>layers,<span class="_"> </span>referred<span class="_"> </span>to<span class="_"> </span>as<span class="_"> </span>top-</div><div class="t m0 x6c h6 y211 ffb fs2 fc0 sc0 ls0 ws0">m</div><div class="t m5 x7f h5 y211 ff1 fs2 fc0 sc0 ls0 ws0">layers,<span class="_"> </span>enable<span class="_"> </span>further<span class="_"> </span>control<span class="_"> </span>ov<span class="_ _b"></span>er<span class="_"> </span>the<span class="_"> </span>allocation<span class="_"> </span>of<span class="_"> </span>a<span class="_"> </span>limited</div><div class="t m5 x6 h5 y212 ff1 fs2 fc0 sc0 ls0 ws0">extra<span class="_"> </span>memory<span class="_"> </span>b<span class="_ _4"></span>udget.<span class="_ _d"> </span>Depending<span class="_"> </span>on<span class="_"> </span>the<span class="_"> </span>number<span class="_"> </span>of<span class="_"> </span>outliers<span class="_"> </span>ident<span class="_ _b"></span>iﬁed,<span class="_"> </span>the<span class="_"> </span>actual<span class="_"> </span>layers<span class="_"> </span>eligible<span class="_"> </span>for<span class="_"> </span>additional<span class="_"> </span>allocation</div><div class="t m5 x6 h5 y213 ff1 fs2 fc0 sc0 ls0 ws0">might<span class="_"> </span>be<span class="_"> </span>fewer<span class="_"> </span>than<span class="_"> </span>the<span class="_"> </span>speciﬁed<span class="_"> </span>v<span class="_ _b"></span>alue</div><div class="t m0 xa8 h6 y213 ffb fs2 fc0 sc0 ls0 ws0">m</div><div class="t m5 x152 h5 y213 ff1 fs2 fc0 sc0 ls0 ws0">.<span class="_ _c"> </span>These<span class="_"> </span>layers<span class="_"> </span>may<span class="_"> </span>also<span class="_"> </span>vary<span class="_"> </span>across<span class="_"> </span>modules.<span class="_ _c"> </span>No<span class="_"> </span>extra<span class="_"> </span>memory<span class="_"> </span>is<span class="_"> </span>assigned<span class="_"> </span>to</div><div class="t m28 x6 h5 y214 ff1 fs2 fc0 sc0 ls0 ws0">modules<span class="_"> </span>without<span class="_"> </span>evident<span class="_"> </span>outliers.<span class="_ _a"> </span>Lastly<span class="_ _4"></span>,<span class="_"> </span>when</div><div class="t m0 x98 h6 y214 ffb fs2 fc0 sc0 ls0 ws0">m</div><div class="t m28 x99 h5 y214 ff1 fs2 fc0 sc0 ls0 ws0">is<span class="_"> </span>set<span class="_"> </span>to<span class="_"> </span>0,<span class="_"> </span>all<span class="_"> </span>layers<span class="_"> </span>identiﬁed<span class="_"> </span>by<span class="_"> </span>the<span class="_"> </span>outlier<span class="_"> </span>detection<span class="_"> </span>algorithm<span class="_"> </span>are</div><div class="t m0 x6 h5 y215 ff1 fs2 fc0 sc0 ls0 ws0">considered<span class="_"> </span>for<span class="_"> </span>additional<span class="_"> </span>allocation.</div><div class="t m0 x6 h3 y216 ff2 fs2 fc0 sc0 ls0 ws0">3.5<span class="_ _14"> </span>Experiments</div><div class="t m2 x6 h5 y217 ff1 fs2 fc0 sc0 ls0 ws0">T<span class="_ _1"></span>o<span class="_ _d"> </span>assess<span class="_ _d"> </span>the<span class="_ _d"> </span>effecti<span class="_ _4"></span>veness<span class="_ _d"> </span>of<span class="_ _d"> </span>the<span class="_ _d"> </span>proposed<span class="_ _d"> </span>SensiBoost<span class="_ _d"> </span>and<span class="_ _d"> </span>KurtBoost<span class="_ _c"> </span>methods,<span class="_ _10"> </span>models<span class="_ _d"> </span>quantized<span class="_ _d"> </span>using<span class="_ _d"> </span>the<span class="_ _d"> </span>two</div><div class="t m0 x6 h5 y218 ff1 fs2 fc0 sc0 ls0 ws0">approaches<span class="_"> </span>were<span class="_"> </span>e<span class="_ _b"></span>valuated<span class="_"> </span>using<span class="_"> </span>the<span class="_"> </span>W<span class="_ _4"></span>ikiT<span class="_ _4"></span>e<span class="_ _4"></span>xt-2<span class="_"> </span>and<span class="_"> </span>C4<span class="_"> </span>datasets<span class="_"> </span>to<span class="_"> </span>measure<span class="_"> </span>the<span class="_"> </span>perplexity<span class="_"> </span>scores.<span class="_ _c"> </span>For<span class="_"> </span>each<span class="_"> </span>proposed</div><div class="t m2 x6 h5 y219 ff1 fs2 fc0 sc0 ls0 ws0">method,<span class="_ _a"> </span>various<span class="_ _a"> </span>boost<span class="_ _c"> </span>stop<span class="_ _a"> </span>and<span class="_ _a"> </span>top-</div><div class="t m0 x153 h6 y219 ffb fs2 fc0 sc0 ls0 ws0">m</div><div class="t m2 xc1 h5 y219 ff1 fs2 fc0 sc0 ls0 ws0">conﬁgurations<span class="_ _a"> </span>were<span class="_ _c"> </span>benchmarked.<span class="_ _11"> </span>Speciﬁcally<span class="_ _4"></span>,<span class="_ _a"> </span>these<span class="_ _c"> </span>experiments<span class="_"> </span>inv<span class="_ _4"></span>olved</div><div class="t m2 x6 h5 y1c ff1 fs2 fc0 sc0 ls0 ws0">benchmarking<span class="_ _a"> </span>two<span class="_ _c"> </span>boost<span class="_ _c"> </span>stop<span class="_ _a"> </span>settings<span class="_ _c"> </span>(2<span class="_ _c"> </span>and<span class="_ _a"> </span>3)<span class="_ _c"> </span>and<span class="_ _c"> </span>four<span class="_ _a"> </span>top-</div><div class="t m0 x154 h6 y1c ffb fs2 fc0 sc0 ls0 ws0">m</div><div class="t m2 x8 h5 y1c ff1 fs2 fc0 sc0 ls0 ws0">values<span class="_"> </span>(1,<span class="_ _c"> </span>2,<span class="_ _c"> </span>3,<span class="_ _d"> </span>and<span class="_ _a"> </span>0)<span class="_ _c"> </span>across<span class="_ _a"> </span>three<span class="_ _c"> </span>Llama<span class="_ _c"> </span>models</div><div class="t m2 x6 h5 y1d ff1 fs2 fc0 sc0 ls0 ws0">under<span class="_"> </span>six<span class="_"> </span>base-bit<span class="_"> </span>budget<span class="_"> </span>conﬁgurations.<span class="_ _a"> </span>Furthermore,<span class="_ _a"> </span>ablation<span class="_"> </span>studies<span class="_"> </span>were<span class="_"> </span>included<span class="_"> </span>to<span class="_"> </span>validate<span class="_"> </span>the<span class="_"> </span>ef<span class="_ _4"></span>ﬁcacy<span class="_"> </span>of<span class="_"> </span>the</div><div class="t m7 x6 h5 y1e ff1 fs2 fc0 sc0 ls0 ws0">proposed<span class="_"> </span>methods.<span class="_ _c"> </span>The<span class="_"> </span>ablation<span class="_"> </span>tests<span class="_ _a"> </span>randomly<span class="_"> </span>select<span class="_"> </span>the<span class="_"> </span>layers<span class="_"> </span>from<span class="_ _a"> </span>a<span class="_"> </span>set<span class="_"> </span>that<span class="_"> </span>explicitly<span class="_"> </span>excludes<span class="_"> </span>the<span class="_"> </span>layers<span class="_"> </span>identiﬁed</div><div class="t m19 x6 h5 y1f ff1 fs2 fc0 sc0 ls0 ws0">by<span class="_"> </span>SensiBoost<span class="_"> </span>or<span class="_"> </span>KurtBoost.<span class="_ _a"> </span>T<span class="_ _4"></span>o<span class="_"> </span>ensure<span class="_"> </span>a<span class="_"> </span>fair<span class="_"> </span>comparison,<span class="_"> </span>the<span class="_"> </span>amount<span class="_"> </span>of<span class="_"> </span>e<span class="_ _b"></span>xtra<span class="_"> </span>memory<span class="_"> </span>and<span class="_"> </span>the<span class="_"> </span>layers<span class="_"> </span>are<span class="_"> </span>identical<span class="_"> </span>to</div><div class="t mb x6 h5 y20 ff1 fs2 fc0 sc0 ls0 ws0">those<span class="_"> </span>used<span class="_"> </span>in<span class="_"> </span>SensiBoost<span class="_"> </span>or<span class="_"> </span>KurtBoost.<span class="_ _c"> </span>The<span class="_"> </span>complete<span class="_"> </span>permutations<span class="_"> </span>of<span class="_"> </span>the<span class="_"> </span>test<span class="_"> </span>cases<span class="_"> </span>consist<span class="_"> </span>of<span class="_"> </span>a<span class="_"> </span>total<span class="_"> </span>of<span class="_"> </span>576<span class="_"> </span>test<span class="_"> </span>cases.</div><div class="t m2 x6 h5 y21a ff1 fs2 fc0 sc0 ls0 ws0">The<span class="_ _10"> </span>comparisons<span class="_ _10"> </span>of<span class="_ _10"> </span>the<span class="_ _10"> </span>different<span class="_ _10"> </span>approaches<span class="_ _10"> </span>were<span class="_ _10"> </span>made<span class="_ _10"> </span>among<span class="_ _11"> </span>SensiBoost,<span class="_ _11"> </span>KurtBoost,<span class="_ _10"> </span>corresponding<span class="_ _11"> </span>ablation</div><div class="t m2 x6 h5 y43 ff1 fs2 fc0 sc0 ls0 ws0">methods,<span class="_ _c"> </span>HQQ,<span class="_ _a"> </span>and<span class="_ _c"> </span>MXQ,<span class="_ _a"> </span>which<span class="_ _c"> </span>are<span class="_ _a"> </span>presented<span class="_ _c"> </span>in<span class="_ _a"> </span>T<span class="_ _4"></span>able<span class="_ _a"> </span>2.<span class="_ _f"> </span>W<span class="_ _4"></span>in-tie-loss<span class="_ _c"> </span>scores<span class="_ _a"> </span>were<span class="_ _c"> </span>used<span class="_ _a"> </span>to<span class="_ _c"> </span>qualitati<span class="_ _b"></span>vely<span class="_ _a"> </span>analyze</div><div class="t m2 x6 h5 y44 ff1 fs2 fc0 sc0 ls0 ws0">the<span class="_"> </span>proposed<span class="_"> </span>methods.<span class="_ _d"> </span>These<span class="_"> </span>scores<span class="_"> </span>were<span class="_"> </span>aggregated<span class="_"> </span>from<span class="_"> </span>the<span class="_"> </span>perplexity<span class="_"> </span>results<span class="_"> </span>benchmarked<span class="_"> </span>and<span class="_"> </span>paired<span class="_"> </span>based<span class="_ _a"> </span>on</div><div class="t m1f x6 h5 y45 ff1 fs2 fc0 sc0 ls0 ws0">T<span class="_ _1"></span>able<span class="_"> </span>2.<span class="_ _c"> </span>Speciﬁcally<span class="_ _4"></span>,<span class="_"> </span>all<span class="_"> </span>perplexity<span class="_"> </span>scores<span class="_"> </span>were<span class="_"> </span>rounded<span class="_"> </span>to<span class="_"> </span>two<span class="_"> </span>decimal<span class="_"> </span>places.<span class="_ _a"> </span>The<span class="_"> </span>perplexity<span class="_"> </span>of<span class="_"> </span>the<span class="_"> </span>primary<span class="_"> </span>method</div><div class="t m2 x6 h5 y46 ff1 fs2 fc0 sc0 ls0 ws0">(SensiBoost<span class="_"> </span>or<span class="_"> </span>KurtBoost)<span class="_"> </span>was<span class="_"> </span>then<span class="_"> </span>subtracted<span class="_"> </span>from<span class="_ _a"> </span>the<span class="_"> </span>comparison<span class="_ _a"> </span>method<span class="_"> </span>to<span class="_"> </span>determine<span class="_ _a"> </span>the<span class="_"> </span>win-tie-loss<span class="_ _a"> </span>score.<span class="_ _d"> </span>A</div><div class="t m2 x6 h5 y47 ff1 fs2 fc0 sc0 ls0 ws0">negati<span class="_ _4"></span>ve<span class="_"> </span>dif<span class="_ _b"></span>ference<span class="_"> </span>awarded<span class="_"> </span>the<span class="_"> </span>primary<span class="_"> </span>method<span class="_"> </span>1<span class="_"> </span>win,<span class="_"> </span>a<span class="_"> </span>dif<span class="_ _4"></span>ference<span class="_"> </span>of<span class="_"> </span>zero<span class="_"> </span>awarded<span class="_"> </span>1<span class="_"> </span>tie,<span class="_"> </span>and<span class="_"> </span>a<span class="_"> </span>positi<span class="_ _b"></span>ve<span class="_"> </span>dif<span class="_ _4"></span>ference</div><div class="t m5 x6 h5 y27 ff1 fs2 fc0 sc0 ls0 ws0">aw<span class="_ _b"></span>arded<span class="_"> </span>1<span class="_ _8"> </span>loss.<span class="_ _c"> </span>Finally<span class="_ _4"></span>,<span class="_"> </span>the<span class="_ _8"> </span>win-tie-loss<span class="_ _8"> </span>scores<span class="_ _8"> </span>were<span class="_"> </span>aggre<span class="_ _4"></span>gated<span class="_"> </span>across<span class="_"> </span>six<span class="_ _8"> </span>quantization<span class="_"> </span>conﬁgurations,<span class="_ _8"> </span>two<span class="_ _8"> </span>stop<span class="_ _8"> </span>settings,</div><div class="t m5 x6 h5 y28 ff1 fs2 fc0 sc0 ls0 ws0">four<span class="_"> </span>top-</div><div class="t m0 x3f h6 y28 ffb fs2 fc0 sc0 ls0 ws0">m</div><div class="t m5 x13a h5 y28 ff1 fs2 fc0 sc0 ls0 ws0">settings,<span class="_"> </span>and<span class="_"> </span>two<span class="_"> </span>ev<span class="_ _4"></span>aluation<span class="_"> </span>datasets,<span class="_"> </span>providing<span class="_"> </span>a<span class="_"> </span>summarized<span class="_"> </span>win-tie-loss<span class="_"> </span>analysis<span class="_"> </span>for<span class="_ _a"> </span>various<span class="_"> </span>method<span class="_"> </span>pairs</div><div class="t m0 x6 h5 y29 ff1 fs2 fc0 sc0 ls0 ws0">across<span class="_"> </span>the<span class="_"> </span>three<span class="_"> </span>Llama<span class="_"> </span>models.</div><div class="t m0 x108 h5 y48 ff1 fs2 fc0 sc0 ls0 ws0">10</div><a class="l" href="#pf7" data-dest-detail='[7,"XYZ",72,117.116,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:954.068000px;bottom:1325.558000px;width:13.446000px;height:9.903000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfa" data-dest-detail='[10,"XYZ",72,541.296,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:492.796000px;bottom:783.802000px;width:5.993000px;height:9.904000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",72,725.455,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:611.806000px;bottom:289.422000px;width:6.073000px;height:9.903000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",72,725.455,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:189.168000px;bottom:245.784000px;width:5.979000px;height:9.904000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[2.000000,0.000000,0.000000,2.000000,0.000000,0.000000]}'></div></div>
