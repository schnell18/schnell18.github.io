<div id="pf1" class="pf w0 h0" data-page-no="1"><div class="pc pc1 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="data:image/png;base64,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"/><div class="t m0 x1 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">T<span class="_ _0"></span><span class="fs1">O<span class="_ _0"></span>W<span class="_ _1"></span>A<span class="_ _0"></span>R<span class="_ _2"></span>D<span class="_ _2"></span>S<span class="_ _3"> </span><span class="fs0">S<span class="_ _2"></span></span>U<span class="_ _0"></span>P<span class="_ _2"></span>E<span class="_ _0"></span>R<span class="_ _2"></span>I<span class="_ _0"></span>O<span class="_ _2"></span>R<span class="_ _3"> </span><span class="fs0">Q<span class="_ _0"></span></span>U<span class="_ _0"></span>A<span class="_ _0"></span>N<span class="_ _2"></span>T<span class="_ _0"></span>I<span class="_ _2"></span>Z<span class="_ _0"></span>A<span class="_ _4"></span>T<span class="_ _2"></span>I<span class="_ _0"></span>O<span class="_ _2"></span>N<span class="_ _3"> </span><span class="fs0">A<span class="_ _5"></span></span>C<span class="_ _2"></span>C<span class="_ _0"></span>U<span class="_ _2"></span>R<span class="_ _0"></span>A<span class="_ _5"></span>C<span class="_ _2"></span>Y<span class="_ _4"></span><span class="fs0">:<span class="_ _6"> </span>A</span></span></div><div class="t m0 x2 h2 y2 ff1 fs0 fc0 sc0 ls0 ws0">L<span class="_ _2"></span><span class="fs1">A<span class="_ _1"></span>Y<span class="_ _2"></span>E<span class="_ _0"></span>R<span class="_ _2"></span><span class="fs0">-<span class="_ _0"></span></span>S<span class="_ _2"></span>E<span class="_ _0"></span>N<span class="_ _2"></span>S<span class="_ _0"></span>I<span class="_ _2"></span>T<span class="_ _0"></span>I<span class="_ _2"></span>V<span class="_ _0"></span>E<span class="_ _7"> </span><span class="fs0">A<span class="_ _2"></span></span>P<span class="_ _0"></span>P<span class="_ _2"></span>RO<span class="_ _5"></span>A<span class="_ _5"></span>C<span class="_ _2"></span>H</span></div><div class="t m0 x3 h3 y3 ff2 fs2 fc0 sc0 ls0 ws0">Feng<span class="_ _8"> </span>Zhang<span class="_ _9"> </span>,<span class="_ _8"> </span>Y<span class="_ _4"></span>anbin<span class="_ _8"> </span>Liu<span class="_ _9"> </span>,<span class="_ _a"> </span>W<span class="_ _4"></span>eihua<span class="_ _8"> </span>Li<span class="_ _9"> </span>,<span class="_ _a"> </span>Jie<span class="_ _8"> </span>Lv<span class="_ _9"> </span>,<span class="_ _a"> </span>Xiaodan<span class="_ _8"> </span>W<span class="_ _4"></span>ang<span class="_ _9"> </span>,<span class="_ _a"> </span>Quan<span class="_ _8"> </span>Bai</div><div class="t m0 x4 h4 y4 ff2 fs3 fc0 sc0 ls0 ws0">A<span class="_ _0"></span><span class="fs4">B<span class="_ _0"></span>S<span class="_ _0"></span>T<span class="_ _0"></span>R<span class="_ _0"></span>AC<span class="_ _0"></span>T</span></div><div class="t m1 x5 h5 y5 ff1 fs2 fc0 sc0 ls0 ws0">Large<span class="_"> </span>V<span class="_ _4"></span>ision<span class="_"> </span>and<span class="_"> </span>Language<span class="_"> </span>Models<span class="_"> </span>ha<span class="_ _b"></span>ve<span class="_"> </span>e<span class="_ _b"></span>xhibited<span class="_"> </span>remarkable<span class="_"> </span>human-like<span class="_"> </span>intelligence<span class="_"> </span>in<span class="_"> </span>tasks<span class="_"> </span>such</div><div class="t m2 x5 h5 y6 ff1 fs2 fc0 sc0 ls0 ws0">as<span class="_ _a"> </span>natural<span class="_ _a"> </span>language<span class="_ _a"> </span>comprehension,<span class="_ _c"> </span>problem-solving,<span class="_ _a"> </span>logical<span class="_ _a"> </span>reasoning,<span class="_ _c"> </span>and<span class="_ _a"> </span>knowledge<span class="_"> </span>retriev<span class="_ _4"></span>al.</div><div class="t m2 x5 h5 y7 ff1 fs2 fc0 sc0 ls0 ws0">Howe<span class="_ _4"></span>ver<span class="_ _4"></span>,<span class="_"> </span>training<span class="_"> </span>and<span class="_"> </span>serving<span class="_"> </span>these<span class="_"> </span>models<span class="_"> </span>require<span class="_"> </span>substantial<span class="_ _a"> </span>computational<span class="_"> </span>resources,<span class="_"> </span>posing<span class="_"> </span>a</div><div class="t m2 x5 h5 y8 ff1 fs2 fc0 sc0 ls0 ws0">signiﬁcant<span class="_"> </span>barrier<span class="_"> </span>to<span class="_"> </span>their<span class="_"> </span>widespread<span class="_"> </span>application<span class="_"> </span>and<span class="_"> </span>further<span class="_"> </span>research.<span class="_ _d"> </span>T<span class="_ _1"></span>o<span class="_ _a"> </span>mitigate<span class="_"> </span>this<span class="_"> </span>challenge,</div><div class="t m3 x5 h5 y9 ff1 fs2 fc0 sc0 ls0 ws0">various<span class="_"> </span>model<span class="_"> </span>compression<span class="_"> </span>techniques<span class="_"> </span>ha<span class="_ _4"></span>ve<span class="_"> </span>been<span class="_"> </span>de<span class="_ _b"></span>veloped<span class="_"> </span>to<span class="_"> </span>reduce<span class="_"> </span>computational<span class="_"> </span>requirements.</div><div class="t m4 x5 h5 ya ff1 fs2 fc0 sc0 ls0 ws0">Nev<span class="_ _4"></span>ertheless,<span class="_"> </span>existing<span class="_"> </span>methods<span class="_"> </span>often<span class="_"> </span>employ<span class="_"> </span>uniform<span class="_"> </span>quantization<span class="_"> </span>conﬁgurations,<span class="_"> </span>failing<span class="_"> </span>to<span class="_"> </span>account</div><div class="t m2 x5 h5 yb ff1 fs2 fc0 sc0 ls0 ws0">for<span class="_"> </span>the<span class="_"> </span>varying<span class="_"> </span>dif<span class="_ _4"></span>ﬁculties<span class="_"> </span>across<span class="_"> </span>different<span class="_"> </span>layers<span class="_"> </span>in<span class="_"> </span>quantizing<span class="_"> </span>large<span class="_"> </span>neural<span class="_"> </span>network<span class="_"> </span>models.<span class="_ _c"> </span>This</div><div class="t m2 x5 h5 yc ff1 fs2 fc0 sc0 ls0 ws0">paper<span class="_ _a"> </span>tackles<span class="_ _c"> </span>this<span class="_ _a"> </span>issue<span class="_ _c"> </span>by<span class="_ _a"> </span>lev<span class="_ _b"></span>eraging<span class="_ _a"> </span>layer-sensitivity<span class="_"> </span>features,<span class="_ _c"> </span>such<span class="_ _a"> </span>as<span class="_ _c"> </span>activ<span class="_ _4"></span>ation<span class="_ _c"> </span>sensiti<span class="_ _b"></span>vity<span class="_ _a"> </span>and</div><div class="t m5 x5 h5 yd ff1 fs2 fc0 sc0 ls0 ws0">weight<span class="_"> </span>distribution<span class="_ _8"> </span>Kurtosis,<span class="_"> </span>to<span class="_ _8"> </span>identify<span class="_"> </span>layers<span class="_"> </span>that<span class="_"> </span>are<span class="_"> </span>challenging<span class="_"> </span>to<span class="_ _8"> </span>quantize<span class="_"> </span>accurately<span class="_"> </span>and<span class="_"> </span>allocate</div><div class="t m6 x5 h5 ye ff1 fs2 fc0 sc0 ls0 ws0">additional<span class="_"> </span>memory<span class="_"> </span>b<span class="_ _b"></span>udget.<span class="_ _c"> </span>The<span class="_"> </span>proposed<span class="_"> </span>methods,<span class="_"> </span>named<span class="_"> </span>SensiBoost<span class="_"> </span>and<span class="_"> </span>K<span class="_ _b"></span>urtBoost,<span class="_"> </span>respecti<span class="_ _b"></span>vely<span class="_ _1"></span>,</div><div class="t m5 x5 h5 yf ff1 fs2 fc0 sc0 ls0 ws0">demonstrate<span class="_"> </span>notable<span class="_"> </span>improv<span class="_ _4"></span>ement<span class="_"> </span>in<span class="_"> </span>quantization<span class="_"> </span>accuracy<span class="_ _4"></span>,<span class="_"> </span>achie<span class="_ _4"></span>ving<span class="_"> </span>up<span class="_"> </span>to<span class="_"> </span>9%<span class="_"> </span>lower<span class="_"> </span>perple<span class="_ _4"></span>xity<span class="_"> </span>with</div><div class="t m0 x5 h5 y10 ff1 fs2 fc0 sc0 ls0 ws0">only<span class="_"> </span>a<span class="_"> </span>2%<span class="_"> </span>increase<span class="_"> </span>in<span class="_"> </span>memory<span class="_"> </span>budget<span class="_"> </span>on<span class="_"> </span>LLama<span class="_"> </span>models<span class="_"> </span>compared<span class="_"> </span>to<span class="_"> </span>the<span class="_"> </span>baseline.</div><div class="t m0 x6 h6 y11 ff3 fs2 fc0 sc0 ls0 ws0">K<span class="_ _5"></span><span class="ff2">eywords<span class="_ _3"> </span><span class="ff1">Quantization<span class="_"> </span><span class="ff4">·<span class="_ _a"> </span></span>Lar<span class="_ _4"></span>ge<span class="_"> </span>Language<span class="_"> </span>Model<span class="_"> </span><span class="ff4">·<span class="_ _a"> </span></span>Linear<span class="_"> </span>Programming<span class="_"> </span><span class="ff4">·<span class="_ _a"> </span></span>T<span class="_ _4"></span>ransformer<span class="_"> </span><span class="ff4">·<span class="_ _a"> </span></span>PTQ<span class="_"> </span><span class="ff4">·<span class="_ _8"> </span></span>LLaMA-2</span></span></div><div class="t m0 x6 h4 y12 ff2 fs3 fc0 sc0 ls0 ws0">1<span class="_ _e"> </span>Introduction</div><div class="t m7 x6 h5 y13 ff1 fs2 fc0 sc0 ls0 ws0">Large<span class="_"> </span>Language<span class="_"> </span>Models<span class="_"> </span>(LLMs)<span class="_"> </span>ha<span class="_ _b"></span>ve<span class="_"> </span>signiﬁcantly<span class="_"> </span>adv<span class="_ _4"></span>anced<span class="_"> </span>artiﬁcial<span class="_ _a"> </span>intelligence,<span class="_"> </span>demonstrating<span class="_"> </span>human-like<span class="_"> </span>capabili-</div><div class="t m8 x6 h5 y14 ff1 fs2 fc0 sc0 ls0 ws0">ties<span class="_"> </span>in<span class="_"> </span>natural<span class="_"> </span>language<span class="_"> </span>comprehension,<span class="_"> </span>problem-solving,<span class="_"> </span>logical<span class="_"> </span>reasoning,<span class="_"> </span>and<span class="_"> </span>kno<span class="_ _4"></span>wledge<span class="_"> </span>retriev<span class="_ _4"></span>al.<span class="_ _c"> </span>These<span class="_"> </span>models</div><div class="t m2 x6 h5 y15 ff1 fs2 fc0 sc0 ls0 ws0">power<span class="_"> </span>a<span class="_"> </span>wide<span class="_"> </span>range<span class="_"> </span>of<span class="_"> </span>applications,<span class="_ _a"> </span>from<span class="_"> </span>chatbots<span class="_"> </span>and<span class="_ _a"> </span>virtual<span class="_"> </span>assistants<span class="_"> </span>to<span class="_ _a"> </span>code<span class="_"> </span>generation<span class="_"> </span>and<span class="_ _a"> </span>scientiﬁc<span class="_"> </span>discovery<span class="_ _4"></span>.</div><div class="t m2 x6 h5 y16 ff1 fs2 fc0 sc0 ls0 ws0">Howe<span class="_ _4"></span>ver<span class="_ _4"></span>,<span class="_ _a"> </span>their<span class="_ _a"> </span>deployment<span class="_ _a"> </span>is<span class="_ _a"> </span>hindered<span class="_ _a"> </span>by<span class="_ _a"> </span>substantial<span class="_ _a"> </span>computational<span class="_ _a"> </span>and<span class="_ _a"> </span>memory<span class="_ _a"> </span>demands,<span class="_ _c"> </span>which<span class="_"> </span>necessitates<span class="_ _a"> </span>the</div><div class="t m0 x6 h5 y17 ff1 fs2 fc0 sc0 ls0 ws0">needs<span class="_"> </span>for<span class="_"> </span>efﬁcient<span class="_"> </span>model<span class="_"> </span>compression<span class="_"> </span>and<span class="_"> </span>quantization<span class="_"> </span>techniques<span class="_"> </span>to<span class="_"> </span>lo<span class="_ _4"></span>w<span class="_"> </span>the<span class="_"> </span>bar<span class="_"> </span>of<span class="_"> </span>entry<span class="_ _4"></span>.</div><div class="t m5 x6 h5 y18 ff1 fs2 fc0 sc0 ls0 ws0">Quantization<span class="_"> </span>techniques<span class="_"> </span>aim<span class="_ _8"> </span>to<span class="_"> </span>reduce<span class="_ _8"> </span>the<span class="_"> </span>memory<span class="_ _8"> </span>footprint<span class="_"> </span>and<span class="_ _8"> </span>computational<span class="_"> </span>requirements<span class="_ _8"> </span>of<span class="_"> </span>LLMs<span class="_ _8"> </span>while<span class="_"> </span>preserving</div><div class="t m9 x6 h5 y19 ff1 fs2 fc0 sc0 ls0 ws0">their<span class="_"> </span>performance.<span class="_ _c"> </span>Existing<span class="_"> </span>quantization<span class="_"> </span>methods,<span class="_ _a"> </span>such<span class="_"> </span>as<span class="_"> </span>A<span class="_ _1"></span>WQ<span class="_ _a"> </span>[</div><div class="t m0 x7 h5 y19 ff1 fs2 fc0 sc0 ls0 ws0">1</div><div class="t m9 x8 h5 y19 ff1 fs2 fc0 sc0 ls0 ws0">],<span class="_"> </span>GPTQ<span class="_"> </span>[</div><div class="t m0 x9 h5 y19 ff1 fs2 fc0 sc0 ls0 ws0">2</div><div class="t m9 xa h5 y19 ff1 fs2 fc0 sc0 ls0 ws0">],<span class="_"> </span>BnB<span class="_"> </span>[</div><div class="t m0 xb h5 y19 ff1 fs2 fc0 sc0 ls0 ws0">3</div><div class="t m9 xc h5 y19 ff1 fs2 fc0 sc0 ls0 ws0">],<span class="_"> </span>and<span class="_"> </span>HQQ<span class="_"> </span>[</div><div class="t m0 xd h5 y19 ff1 fs2 fc0 sc0 ls0 ws0">4</div><div class="t m9 xe h5 y19 ff1 fs2 fc0 sc0 ls0 ws0">],<span class="_"> </span>predominantly</div><div class="t m2 x6 h5 y1a ff1 fs2 fc0 sc0 ls0 ws0">employ<span class="_ _a"> </span>uniform<span class="_ _c"> </span>quantization<span class="_ _a"> </span>conﬁgurations.<span class="_ _f"> </span>While<span class="_ _a"> </span>effecti<span class="_ _b"></span>ve<span class="_"> </span>to<span class="_ _c"> </span>some<span class="_ _c"> </span>extent,<span class="_ _a"> </span>these<span class="_ _c"> </span>approaches<span class="_ _a"> </span>fail<span class="_ _a"> </span>to<span class="_ _c"> </span>consider<span class="_ _a"> </span>the</div><div class="t m0 x6 h5 y1b ff1 fs2 fc0 sc0 ls0 ws0">varying<span class="_"> </span>quantization<span class="_"> </span>dif<span class="_ _4"></span>ﬁculty<span class="_"> </span>across<span class="_"> </span>different<span class="_"> </span>layers<span class="_"> </span>of<span class="_"> </span>billion-scale<span class="_"> </span>models.</div><div class="t m2 x6 h5 y1c ff1 fs2 fc0 sc0 ls0 ws0">Deep<span class="_ _d"> </span>neural<span class="_ _d"> </span>network<span class="_ _10"> </span>model’<span class="_ _4"></span>s<span class="_ _d"> </span>weights<span class="_ _10"> </span>are<span class="_ _d"> </span>typically<span class="_ _10"> </span>initialized<span class="_ _d"> </span>using<span class="_ _d"> </span>the<span class="_ _10"> </span>Kaiming<span class="_ _d"> </span>[</div><div class="t m0 xf h5 y1c ff1 fs2 fc0 sc0 ls0 ws0">5</div><div class="t m2 x10 h5 y1c ff1 fs2 fc0 sc0 ls0 ws0">]<span class="_ _d"> </span>or<span class="_ _d"> </span>the<span class="_ _10"> </span>Xavier<span class="_ _d"> </span>initialization</div><div class="t m8 x6 h5 y1d ff1 fs2 fc0 sc0 ls0 ws0">method<span class="_"> </span>[</div><div class="t m0 x5 h5 y1d ff1 fs2 fc0 sc0 ls0 ws0">6</div><div class="t m8 x11 h5 y1d ff1 fs2 fc0 sc0 ls0 ws0">],<span class="_"> </span>leading<span class="_"> </span>to<span class="_"> </span>a<span class="_"> </span>zero-centered<span class="_"> </span>normal<span class="_ _8"> </span>distribution<span class="_ _8"> </span>with<span class="_"> </span>a<span class="_"> </span>standard<span class="_"> </span>de<span class="_ _4"></span>viation<span class="_"> </span>usually<span class="_"> </span>less<span class="_"> </span>than<span class="_"> </span>1.<span class="_ _c"> </span>Outliers<span class="_"> </span>are</div><div class="t m2 x6 h5 y1e ff1 fs2 fc0 sc0 ls0 ws0">introduced<span class="_"> </span>during<span class="_ _a"> </span>model<span class="_ _a"> </span>training<span class="_ _a"> </span>due<span class="_"> </span>to<span class="_ _a"> </span>several<span class="_"> </span>reasons.<span class="_ _d"> </span>For<span class="_ _a"> </span>example,<span class="_"> </span>An<span class="_ _a"> </span>et<span class="_ _a"> </span>al.<span class="_"> </span>[</div><div class="t m0 x12 h5 y1e ff1 fs2 fc0 sc0 ls0 ws0">7</div><div class="t m2 x13 h5 y1e ff1 fs2 fc0 sc0 ls0 ws0">]<span class="_"> </span>revealed<span class="_"> </span>that<span class="_"> </span>softmax<span class="_ _a"> </span>attention</div><div class="t m2 x6 h5 y1f ff1 fs2 fc0 sc0 ls0 ws0">is<span class="_ _c"> </span>the<span class="_ _d"> </span>root<span class="_ _c"> </span>cause<span class="_ _d"> </span>of<span class="_ _c"> </span>outliers<span class="_ _d"> </span>in<span class="_ _c"> </span>transformer-based<span class="_ _c"> </span>neural<span class="_ _d"> </span>network<span class="_ _c"> </span>models.<span class="_ _7"> </span>Additionally<span class="_ _4"></span>,<span class="_ _d"> </span>multiple<span class="_ _c"> </span>studies[</div><div class="t m0 x14 h5 y1f ff1 fs2 fc0 sc0 ls0 ws0">8</div><div class="t m2 x15 h5 y1f ff1 fs2 fc0 sc0 ls0 ws0">,</div><div class="t m0 x16 h5 y1f ff1 fs2 fc0 sc0 ls0 ws0">9</div><div class="t m2 x17 h5 y1f ff1 fs2 fc0 sc0 ls0 ws0">,</div><div class="t m0 x18 h5 y1f ff1 fs2 fc0 sc0 ls0 ws0">10</div><div class="t m2 x19 h5 y1f ff1 fs2 fc0 sc0 ls0 ws0">]</div><div class="t m2 x6 h5 y20 ff1 fs2 fc0 sc0 ls0 ws0">discov<span class="_ _b"></span>ered<span class="_"> </span>that<span class="_ _a"> </span>layer<span class="_ _a"> </span>normalization<span class="_ _a"> </span>contributes<span class="_"> </span>to<span class="_ _a"> </span>the<span class="_ _a"> </span>introduction<span class="_ _a"> </span>of<span class="_ _a"> </span>outliers.<span class="_ _10"> </span>W<span class="_ _4"></span>eights<span class="_"> </span>with<span class="_ _a"> </span>signiﬁcant<span class="_ _a"> </span>outliers<span class="_"> </span>are</div><div class="t ma x6 h5 y21 ff1 fs2 fc0 sc0 ls0 ws0">challenging<span class="_"> </span>to<span class="_"> </span>quantize<span class="_"> </span>accurately<span class="_"> </span>since<span class="_"> </span>the<span class="_"> </span>accommodation<span class="_"> </span>of<span class="_"> </span>outliers<span class="_"> </span>squeezes<span class="_"> </span>most<span class="_"> </span>normal<span class="_"> </span>weights<span class="_"> </span>into<span class="_"> </span>a<span class="_"> </span>narrower</div><div class="t mb x6 h5 y22 ff1 fs2 fc0 sc0 ls0 ws0">range,<span class="_"> </span>resulting<span class="_"> </span>in<span class="_"> </span>an<span class="_"> </span>imprecise<span class="_"> </span>representation<span class="_"> </span>of<span class="_"> </span>these<span class="_"> </span>weights.<span class="_ _d"> </span>The<span class="_"> </span>une<span class="_ _b"></span>ven<span class="_"> </span>presence<span class="_"> </span>of<span class="_"> </span>outliers<span class="_"> </span>across<span class="_"> </span>layers<span class="_"> </span>leads<span class="_"> </span>to</div><div class="t mc x6 h5 y23 ff1 fs2 fc0 sc0 ls0 ws0">varying<span class="_"> </span>quantization<span class="_"> </span>dif<span class="_ _4"></span>ﬁculty<span class="_"> </span>across<span class="_"> </span>layers<span class="_"> </span>in<span class="_"> </span>a<span class="_"> </span>particular<span class="_"> </span>LLM.<span class="_"> </span>As<span class="_"> </span>illustrated<span class="_ _a"> </span>in<span class="_"> </span>Figure<span class="_"> </span>1a<span class="_"> </span>and<span class="_"> </span>Figure<span class="_"> </span>1b,<span class="_"> </span>the<span class="_"> </span>weight</div><div class="t m0 x6 h5 y24 ff1 fs2 fc0 sc0 ls0 ws0">magnitudes<span class="_"> </span>in<span class="_"> </span>the<span class="_"> </span><span class="ff5">self_attn.o_proj<span class="_ _8"> </span></span>module<span class="_"> </span>differ<span class="_"> </span>signiﬁcantly<span class="_"> </span>between<span class="_"> </span>the<span class="_"> </span>second<span class="_"> </span>layer<span class="_"> </span>and<span class="_"> </span>the<span class="_"> </span>last<span class="_"> </span>layer<span class="_ _4"></span>.<span class="_ _c"> </span>While</div><div class="t m2 x6 h5 y25 ff1 fs2 fc0 sc0 ls0 ws0">the<span class="_"> </span>last<span class="_ _a"> </span>layer<span class="_ _c"> </span>sho<span class="_ _4"></span>ws<span class="_ _c"> </span>substantial<span class="_"> </span>outliers,<span class="_ _a"> </span>the<span class="_ _c"> </span>second<span class="_"> </span>layer<span class="_ _a"> </span>exhibits<span class="_"> </span>no<span class="_ _c"> </span>notable<span class="_"> </span>outliers.<span class="_ _11"> </span>This<span class="_"> </span>suggests<span class="_ _a"> </span>that<span class="_ _c"> </span>a<span class="_"> </span>uniform</div><div class="t m0 x6 h5 y26 ff1 fs2 fc0 sc0 ls0 ws0">quantization<span class="_"> </span>approach<span class="_"> </span>may<span class="_"> </span>not<span class="_"> </span>be<span class="_"> </span>optimal.</div><div class="t m7 x6 h5 y27 ff1 fs2 fc0 sc0 ls0 ws0">T<span class="_ _1"></span>o<span class="_"> </span>address<span class="_ _a"> </span>this,<span class="_"> </span>MXQ<span class="_"> </span>[</div><div class="t m0 x1a h5 y27 ff1 fs2 fc0 sc0 ls0 ws0">11</div><div class="t m7 x1b h5 y27 ff1 fs2 fc0 sc0 ls0 ws0">]<span class="_"> </span>introduced<span class="_"> </span>a<span class="_"> </span>mixed-integer<span class="_"> </span>linear<span class="_"> </span>programming<span class="_"> </span>(MiLP)<span class="_"> </span>based<span class="_"> </span>approach<span class="_"> </span>to<span class="_"> </span>assign<span class="_"> </span>dif<span class="_ _b"></span>ferenti-</div><div class="t md x6 h5 y28 ff1 fs2 fc0 sc0 ls0 ws0">ated<span class="_"> </span>quantization<span class="_"> </span>conﬁgurations<span class="_"> </span>while<span class="_"> </span>maintaining<span class="_"> </span>an<span class="_"> </span>overall<span class="_"> </span>memory<span class="_"> </span>budget.<span class="_ _a"> </span>Howe<span class="_ _b"></span>ver<span class="_ _4"></span>,<span class="_"> </span>despite<span class="_"> </span>its<span class="_"> </span>adaptiv<span class="_ _b"></span>e<span class="_"> </span>allocation</div><div class="t me x6 h5 y29 ff1 fs2 fc0 sc0 ls0 ws0">strategy<span class="_ _1"></span>,<span class="_ _a"> </span>MXQ-quantized<span class="_"> </span>models<span class="_"> </span>often<span class="_"> </span>underperform<span class="_"> </span>compared<span class="_ _a"> </span>to<span class="_"> </span>the<span class="_"> </span>baseline<span class="_"> </span>methods<span class="_"> </span>such<span class="_ _a"> </span>as<span class="_"> </span>HQQ,<span class="_"> </span>BnB,<span class="_"> </span>and<span class="_ _a"> </span>A<span class="_ _1"></span>WQ,</div><a class="l" href="https://orcid.org/0009-0007-1891-6403"><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,255);position:absolute;left:366.828000px;bottom:1191.820000px;width:7.854000px;height:28.175000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://orcid.org/0000-0003-4724-8065"><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,255);position:absolute;left:490.152000px;bottom:1191.820000px;width:7.854000px;height:28.175000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://orcid.org/0000-0001-9215-4979"><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,255);position:absolute;left:606.104000px;bottom:1191.820000px;width:7.854000px;height:28.175000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://orcid.org/0009-0001-8713-3660"><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,255);position:absolute;left:685.694000px;bottom:1191.820000px;width:7.853000px;height:28.175000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://orcid.org/0009-0008-2159-2339"><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,255);position:absolute;left:839.284000px;bottom:1191.820000px;width:7.854000px;height:28.175000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://orcid.org/0000-0003-1214-6317"><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,255);position:absolute;left:947.684000px;bottom:1191.820000px;width:7.854000px;height:28.175000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,469.866,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:659.996000px;bottom:512.016000px;width:5.974000px;height:7.747000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,442.411,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:749.160000px;bottom:512.016000px;width:5.973000px;height:7.747000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,417.527,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:823.072000px;bottom:511.818000px;width:5.974000px;height:7.846000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,391.527,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:936.830000px;bottom:512.016000px;width:5.974000px;height:7.747000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,376.994,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:832.016000px;bottom:435.404000px;width:5.974000px;height:7.846000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,351.553,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:213.374000px;bottom:413.586000px;width:5.974000px;height:7.846000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,315.202,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:803.410000px;bottom:391.768000px;width:5.974000px;height:7.577000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,289.88,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:1007.094000px;bottom:369.950000px;width:5.973000px;height:7.846000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,264.318,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:1028.704000px;bottom:369.710000px;width:5.974000px;height:7.966000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,228.087,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:1050.314000px;bottom:369.950000px;width:10.955000px;height:7.846000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",72,725.455,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:849.510000px;bottom:278.562000px;width:10.369000px;height:9.904000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",72,725.455,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:963.820000px;bottom:278.562000px;width:10.925000px;height:9.904000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,202.526,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:325.252000px;bottom:184.644000px;width:10.955000px;height:7.747000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[2.000000,0.000000,0.000000,2.000000,0.000000,0.000000]}'></div></div>
