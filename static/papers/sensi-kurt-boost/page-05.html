<div id="pf5" class="pf w0 h0" data-page-no="5"><div class="pc pc5 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="data:image/png;base64,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"/><div class="t m2 x6 h5 y6d ff1 fs2 fc0 sc0 ls0 ws0">accuracy<span class="_ _1"></span>.<span class="_ _3"> </span>Additionally<span class="_ _4"></span>,<span class="_ _c"> </span>NF4<span class="_ _a"> </span>employs<span class="_ _c"> </span>the<span class="_ _c"> </span>double<span class="_ _a"> </span>quantization<span class="_ _c"> </span>technique<span class="_ _c"> </span>to<span class="_ _c"> </span>reduce<span class="_ _c"> </span>the<span class="_ _a"> </span>overhead<span class="_ _a"> </span>introduced<span class="_ _c"> </span>by<span class="_ _c"> </span>the</div><div class="t m0 x6 h5 ydb ff1 fs2 fc0 sc0 ls0 ws0">granular<span class="_"> </span>grouping<span class="_"> </span>scheme,<span class="_"> </span>a<span class="_"> </span>widely<span class="_"> </span>adopted<span class="_"> </span>strategy<span class="_"> </span>by<span class="_"> </span>other<span class="_"> </span>state-of-the-art<span class="_"> </span>quantization<span class="_"> </span>methods.</div><div class="t m2 x6 h3 ydc ff2 fs2 fc0 sc0 ls0 ws0">MXQ<span class="_ _a"> </span><span class="ff1">[</span></div><div class="t m0 x3a h5 ydc ff1 fs2 fc0 sc0 ls0 ws0">3</div><div class="t m2 x5 h5 ydc ff1 fs2 fc0 sc0 ls0 ws0">]<span class="_ _a"> </span>allocates<span class="_ _a"> </span>optimal<span class="_ _a"> </span>conﬁgurations<span class="_ _a"> </span>that<span class="_ _c"> </span>minimize<span class="_"> </span>the<span class="_ _a"> </span>sum<span class="_ _c"> </span>of<span class="_"> </span>Frobenius<span class="_ _c"> </span>norm<span class="_"> </span>of<span class="_ _c"> </span>the<span class="_"> </span>difference<span class="_"> </span>between<span class="_ _c"> </span>the</div><div class="t m2 x6 h5 ydd ff1 fs2 fc0 sc0 ls0 ws0">full-precision<span class="_"> </span>weight<span class="_"> </span>matrices<span class="_"> </span>and<span class="_"> </span>their<span class="_"> </span>quantized<span class="_"> </span>counterparts<span class="_"> </span>while<span class="_"> </span>maintaining<span class="_"> </span>the<span class="_"> </span>o<span class="_ _4"></span>verall<span class="_"> </span>memory<span class="_"> </span>consumption</div><div class="t m2 x6 h5 yde ff1 fs2 fc0 sc0 ls0 ws0">within<span class="_ _d"> </span>constraints<span class="_ _d"> </span>set<span class="_ _10"> </span>by<span class="_ _d"> </span>a<span class="_ _d"> </span>global<span class="_ _10"> </span>bit<span class="_ _d"> </span>budget<span class="_ _d"> </span>per<span class="_ _d"> </span>parameter<span class="_ _4"></span>.<span class="_ _1a"> </span>MXQ<span class="_ _d"> </span>can<span class="_ _d"> </span>be<span class="_ _10"> </span>formulated<span class="_ _d"> </span>as<span class="_ _d"> </span>a<span class="_ _10"> </span>Mixed-Inte<span class="_ _b"></span>ger<span class="_ _d"> </span>Linear</div><div class="t m0 x6 h5 ydf ff1 fs2 fc0 sc0 ls0 ws0">Programming<span class="_"> </span>[24]<span class="_"> </span>problem<span class="_"> </span>as<span class="_"> </span>denoted<span class="_"> </span>in<span class="_"> </span>Equation<span class="_"> </span>9:</div><div class="t m0 x24 h6 ye0 ffd fs2 fc0 sc0 ls0 ws0">arg<span class="_ _12"> </span>min</div><div class="t m0 xbf hd ye1 ffe fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 x24 h10 ye2 ff12 fs8 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2 hd ye1 ffe fs7 fc0 sc0 ls0 ws0">,c</div><div class="t m0 x25 h10 ye2 ff12 fs8 fc0 sc0 ls0 ws0">2</div><div class="t m0 xaf hc ye1 ffe fs7 fc0 sc0 ls0 ws0">,<span class="ffc">···<span class="_ _13"> </span></span>,c</div><div class="t m0 x7a he ye3 ff10 fs8 fc0 sc0 ls0 ws0">N</div><div class="t m0 xc0 hf ye4 ff11 fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xc1 hc ye5 ffe fs7 fc0 sc0 ls0 ws0">i<span class="ffc">∈{<span class="fff">1</span></span>,...N<span class="_ _0"></span><span class="ffc">}</span></div><div class="t m0 x62 hd ye6 ffe fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 x32 he ye7 ff10 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 x50 hc ye6 ffc fs7 fc0 sc0 ls0 ws0">∈<span class="ffe">C</span></div><div class="t m0 x51 hf ye8 ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x51 hf ye9 ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x51 hf yea ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x6d h6 ye0 ffb fs2 fc0 sc0 ls0 ws0">W</div><div class="t m0 x52 hc yeb fff fs7 fc0 sc0 ls0 ws0">(<span class="ffe">i</span>)</div><div class="t m0 x36 h6 ye0 ff4 fs2 fc0 sc0 ls0 ws0">−</div><div class="t m0 xc2 h6 yec ffd fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 xb1 h6 ye0 ffb fs2 fc0 sc0 ls0 ws0">W</div><div class="t m0 x4f hc yeb fff fs7 fc0 sc0 ls0 ws0">(<span class="ffe">i</span>)</div><div class="t m0 xa3 hd yed ffe fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 x8d he yee ff10 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 xc3 hf ye8 ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xc3 hf ye9 ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xc3 hf yea ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x76 hd yef ffe fs7 fc0 sc0 ls0 ws0">F</div><div class="t m0 xc4 h6 yf0 ffd fs2 fc0 sc0 ls0 ws0">s<span class="ffb">.</span>t<span class="ffb">.</span></div><div class="t m0 xc0 hf yf1 ff11 fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xc1 hc yf2 ffe fs7 fc0 sc0 ls0 ws0">i<span class="ffc">∈{<span class="fff">1</span></span>,...N<span class="_ _0"></span><span class="ffc">}</span></div><div class="t m0 x62 hd yf3 ffe fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 x32 he yf4 ff10 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 x50 hc yf3 ffc fs7 fc0 sc0 ls0 ws0">∈<span class="ffe">C</span></div><div class="t m0 x51 h6 yf0 ff5 fs2 fc0 sc0 ls0 ws0">stor<span class="ffd">(<span class="ffb">W</span></span></div><div class="t m0 x7f hc yf5 fff fs7 fc0 sc0 ls0 ws0">(<span class="ffe">i</span>)</div><div class="t m0 x8c h6 yf0 ffb fs2 fc0 sc0 ls0 ws0">,<span class="_ _13"> </span>c</div><div class="t m0 xc5 hd yf6 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xb7 h6 yf0 ffd fs2 fc0 sc0 ls0 ws0">)<span class="_"> </span><span class="ff4">≤<span class="_ _a"> </span><span class="ffb">β<span class="_ _0"></span>,</span></span></div><div class="t m0 xc6 h6 yf7 ffd fs2 fc0 sc0 ls0 ws0">where<span class="_ _1b"> </span><span class="ff5">stor</span>(<span class="ffb">W</span></div><div class="t m0 xc7 hc yf8 fff fs7 fc0 sc0 ls0 ws0">(<span class="ffe">i</span>)</div><div class="t m0 x6d h6 yf7 ffb fs2 fc0 sc0 ls0 ws0">,<span class="_ _13"> </span>c</div><div class="t m0 x49 hd yf9 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x72 h6 yf7 ffd fs2 fc0 sc0 ls0 ws0">)<span class="_"> </span>=<span class="_"> </span><span class="ff4">|<span class="ffb">W</span></span></div><div class="t m0 xa3 hc yf8 fff fs7 fc0 sc0 ls0 ws0">(<span class="ffe">i</span>)</div><div class="t m0 xb7 h6 yf7 ff4 fs2 fc0 sc0 ls0 ws0">|<span class="_ _8"> </span>·</div><div class="t m0 x8 hf yfa ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xc8 h6 yf7 ffb fs2 fc0 sc0 ls0 ws0">b</div><div class="t m0 xc9 hc yf9 fff fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xca h6 yf7 ffd fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 xaa h6 yfb ffd fs2 fc0 sc0 ls0 ws0">2<span class="ffb">b</span></div><div class="t m0 xcb hc yfc fff fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xcc h6 yfd ffb fs2 fc0 sc0 ls0 ws0">g<span class="_ _5"></span><span class="ffd">1</span></div><div class="t m0 xbb h6 yf7 ffd fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 x82 h6 yfb ffd fs2 fc0 sc0 ls0 ws0">32</div><div class="t m0 xcd h6 yfd ffb fs2 fc0 sc0 ls0 ws0">g</div><div class="t m0 xce hc yfe fff fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xcf h6 yfd ff4 fs2 fc0 sc0 ls0 ws0">·<span class="_ _8"> </span><span class="ffb">g</span></div><div class="t m0 xd0 hc yfe fff fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xd1 hf yfa ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x53 h5 yff ff1 fs2 fc0 sc0 ls0 ws0">(9)</div><div class="t m2 x6 h5 y100 ff1 fs2 fc0 sc0 ls0 ws0">where</div><div class="t m0 x2c h6 y100 ffb fs2 fc0 sc0 ls0 ws0">c</div><div class="t m0 x3a hd y101 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xd2 h6 y100 ffd fs2 fc0 sc0 ls0 ws0">=<span class="_ _c"> </span>(<span class="ffb">b</span></div><div class="t m0 xd3 hc y101 fff fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xd4 h6 y100 ffb fs2 fc0 sc0 ls0 ws0">,<span class="_ _13"> </span>g</div><div class="t m0 xd5 hc y101 fff fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xd6 h6 y100 ffb fs2 fc0 sc0 ls0 ws0">,<span class="_ _13"> </span>b</div><div class="t m0 xd7 hc y101 fff fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x84 h6 y100 ffb fs2 fc0 sc0 ls0 ws0">,<span class="_ _13"> </span>g</div><div class="t m0 x69 hc y101 fff fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x1b h6 y100 ffd fs2 fc0 sc0 ls0 ws0">)</div><div class="t m2 xd8 h5 y100 ff1 fs2 fc0 sc0 ls0 ws0">denotes<span class="_"> </span>the<span class="_ _a"> </span>conﬁguration<span class="_"> </span>parameters<span class="_ _a"> </span>used<span class="_ _a"> </span>to<span class="_ _a"> </span>quantize<span class="_"> </span>the</div><div class="t m0 xf h6 y100 ffb fs2 fc0 sc0 ls0 ws0">i</div><div class="t m2 xd1 h5 y100 ff1 fs2 fc0 sc0 ls0 ws0">th<span class="_"> </span>matrix<span class="_ _a"> </span>of<span class="_"> </span>the<span class="_ _a"> </span>LLM,</div><div class="t m0 xd9 h6 y100 ffb fs2 fc0 sc0 ls0 ws0">b</div><div class="t m0 xda hc y101 fff fs7 fc0 sc0 ls0 ws0">1</div><div class="t m2 xdb h5 y100 ff1 fs2 fc0 sc0 ls0 ws0">and</div><div class="t m0 x6 h6 y102 ffb fs2 fc0 sc0 ls0 ws0">g</div><div class="t m0 xdc hc y103 fff fs7 fc0 sc0 ls0 ws0">1</div><div class="t m2 x39 h5 y102 ff1 fs2 fc0 sc0 ls0 ws0">represent<span class="_ _a"> </span>the<span class="_ _a"> </span>bit<span class="_ _a"> </span>width<span class="_ _a"> </span>and<span class="_ _a"> </span>group<span class="_ _c"> </span>size<span class="_"> </span>for<span class="_ _a"> </span>quantizing<span class="_ _c"> </span>weights,</div><div class="t m0 xb2 h6 y102 ffb fs2 fc0 sc0 ls0 ws0">b</div><div class="t m0 xdd hc y103 fff fs7 fc0 sc0 ls0 ws0">2</div><div class="t m2 x77 h5 y102 ff1 fs2 fc0 sc0 ls0 ws0">and</div><div class="t m0 xcc h6 y102 ffb fs2 fc0 sc0 ls0 ws0">g</div><div class="t m0 xde hc y103 fff fs7 fc0 sc0 ls0 ws0">2</div><div class="t m2 xdf h5 y102 ff1 fs2 fc0 sc0 ls0 ws0">indicate<span class="_ _a"> </span>the<span class="_ _a"> </span>bit<span class="_ _a"> </span>width<span class="_ _a"> </span>and<span class="_ _a"> </span>group<span class="_ _c"> </span>size<span class="_"> </span>to</div><div class="t m2 x6 h5 y104 ff1 fs2 fc0 sc0 ls0 ws0">quantize<span class="_"> </span>metadata,<span class="_"> </span>such<span class="_"> </span>as<span class="_"> </span>zero<span class="_ _a"> </span>points<span class="_"> </span>and<span class="_"> </span>scales.</div><div class="t m0 xe0 h6 y104 ffb fs2 fc0 sc0 ls0 ws0">C</div><div class="t m2 x5d h5 y104 ff1 fs2 fc0 sc0 ls0 ws0">is<span class="_"> </span>the<span class="_"> </span>set<span class="_"> </span>of<span class="_"> </span>12<span class="_ _a"> </span>possible<span class="_"> </span>conﬁgurations.<span class="_ _d"> </span>Additionally<span class="_ _4"></span>,</div><div class="t m0 xe1 h6 y104 ffb fs2 fc0 sc0 ls0 ws0">N</div><div class="t m2 xda h5 y104 ff1 fs2 fc0 sc0 ls0 ws0">is<span class="_"> </span>the</div><div class="t m2 x6 h5 y105 ff1 fs2 fc0 sc0 ls0 ws0">number<span class="_"> </span>of<span class="_"> </span>weight<span class="_"> </span>matrices<span class="_"> </span>to<span class="_"> </span>be<span class="_"> </span>quantized,</div><div class="t m0 x63 h6 y105 ffb fs2 fc0 sc0 ls0 ws0">W</div><div class="t m0 xe2 hc y106 fff fs7 fc0 sc0 ls0 ws0">(<span class="ffe">i</span>)</div><div class="t m2 xe3 h5 y105 ff1 fs2 fc0 sc0 ls0 ws0">and</div><div class="t m0 x6c h6 y107 ffd fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 xe4 h6 y105 ffb fs2 fc0 sc0 ls0 ws0">W</div><div class="t m0 x41 hc y106 fff fs7 fc0 sc0 ls0 ws0">(<span class="ffe">i</span>)</div><div class="t m2 x65 h5 y105 ff1 fs2 fc0 sc0 ls0 ws0">are<span class="_"> </span>the</div><div class="t m0 xc8 h6 y105 ffb fs2 fc0 sc0 ls0 ws0">i</div><div class="t m2 xe5 h5 y105 ff1 fs2 fc0 sc0 ls0 ws0">th<span class="_"> </span>full-precision<span class="_"> </span>and<span class="_"> </span>quantized<span class="_"> </span>weight<span class="_"> </span>matrices,</div><div class="t m1e x6 h5 y108 ff1 fs2 fc0 sc0 ls0 ws0">respectiv<span class="_ _4"></span>ely<span class="_ _4"></span>.<span class="_ _c"> </span>The<span class="_"> </span>parameter</div><div class="t m0 xc6 h6 y108 ffb fs2 fc0 sc0 ls0 ws0">β</div><div class="t m1e x24 h5 y108 ff1 fs2 fc0 sc0 ls0 ws0">denotes<span class="_"> </span>the<span class="_"> </span>overall<span class="_"> </span>memory<span class="_"> </span>b<span class="_ _4"></span>udget<span class="_"> </span>in<span class="_"> </span>megabytes.<span class="_ _c"> </span>By<span class="_"> </span>introducing</div><div class="t m0 xe6 h6 y108 ffb fs2 fc0 sc0 ls0 ws0">M<span class="_ _10"> </span><span class="ffd">=<span class="_"> </span><span class="ff4">|</span></span>C<span class="_ _2"></span><span class="ff4">|<span class="_ _12"> </span>×<span class="_ _8"> </span></span>N</div><div class="t m1e xe7 h5 y108 ff1 fs2 fc0 sc0 ls0 ws0">binary</div><div class="t m5 x6 h5 y109 ff1 fs2 fc0 sc0 ls0 ws0">decision<span class="_"> </span>variables,<span class="_"> </span>Equation<span class="_"> </span>9<span class="_"> </span>is<span class="_"> </span>further<span class="_"> </span>con<span class="_ _4"></span>verted<span class="_"> </span>to<span class="_"> </span>standard<span class="_"> </span>LP<span class="_"> </span>formulation<span class="_"> </span>[</div><div class="t m0 xa h5 y109 ff1 fs2 fc0 sc0 ls0 ws0">25</div><div class="t m5 xa2 h5 y109 ff1 fs2 fc0 sc0 ls0 ws0">]<span class="_"> </span>so<span class="_"> </span>that<span class="_"> </span>it<span class="_"> </span>can<span class="_"> </span>be<span class="_"> </span>solved<span class="_"> </span>ef<span class="_ _4"></span>ﬁciently<span class="_ _a"> </span>by</div><div class="t m0 x6 h5 y10a ff1 fs2 fc0 sc0 ls0 ws0">off-the-shelf<span class="_"> </span>LP<span class="_"> </span>solv<span class="_ _4"></span>ers<span class="_"> </span>such<span class="_"> </span>as<span class="_"> </span>Gurobi<span class="_"> </span>[26]<span class="_"> </span>and<span class="_"> </span>HiGHS<span class="_"> </span>[24].</div><div class="t m2 x6 h5 y10b ff1 fs2 fc0 sc0 ls0 ws0">Except<span class="_"> </span>for<span class="_"> </span>the<span class="_"> </span>relativ<span class="_ _b"></span>ely<span class="_"> </span>new<span class="_"> </span>MXQ<span class="_"> </span>approach,<span class="_"> </span>these<span class="_"> </span>methods<span class="_"> </span>hav<span class="_ _4"></span>e<span class="_"> </span>been<span class="_"> </span>adopted<span class="_ _a"> </span>extensi<span class="_ _4"></span>vely<span class="_"> </span>in<span class="_"> </span>the<span class="_"> </span>industry<span class="_ _4"></span>,<span class="_"> </span>demon-</div><div class="t m2 x6 h5 y10c ff1 fs2 fc0 sc0 ls0 ws0">strating<span class="_ _c"> </span>their<span class="_ _d"> </span>practicality<span class="_ _c"> </span>and<span class="_ _c"> </span>efﬁcacy<span class="_ _1"></span>.<span class="_ _7"> </span>Nev<span class="_ _4"></span>ertheless,<span class="_ _d"> </span>the<span class="_ _d"> </span>limitations<span class="_ _c"> </span>of<span class="_ _c"> </span>these<span class="_ _d"> </span>methods<span class="_ _c"> </span>are<span class="_ _c"> </span>worth<span class="_ _c"> </span>discussing.<span class="_ _7"> </span>First,</div><div class="t m12 x6 h5 y10d ff1 fs2 fc0 sc0 ls0 ws0">quantization<span class="_"> </span>methods<span class="_"> </span>such<span class="_"> </span>as<span class="_"> </span>GPTQ<span class="_"> </span>and<span class="_"> </span>A<span class="_ _4"></span>WQ<span class="_"> </span>require<span class="_"> </span>curated<span class="_"> </span>calibration<span class="_"> </span>datasets,<span class="_"> </span>making<span class="_"> </span>it<span class="_"> </span>challenging<span class="_"> </span>to<span class="_ _a"> </span>generalize</div><div class="t m2 x6 h5 y10e ff1 fs2 fc0 sc0 ls0 ws0">these<span class="_ _a"> </span>methods<span class="_ _a"> </span>to<span class="_ _c"> </span>other<span class="_ _a"> </span>large<span class="_ _a"> </span>neural<span class="_ _a"> </span>networks<span class="_ _c"> </span>such<span class="_ _a"> </span>as<span class="_ _a"> </span>vision<span class="_ _c"> </span>models,<span class="_ _a"> </span>which<span class="_ _c"> </span>are<span class="_ _a"> </span>trained<span class="_ _a"> </span>on<span class="_ _c"> </span>a<span class="_ _a"> </span>mixture<span class="_ _c"> </span>of<span class="_ _a"> </span>textual<span class="_ _a"> </span>and</div><div class="t m16 x6 h5 y10f ff1 fs2 fc0 sc0 ls0 ws0">image<span class="_"> </span>data.<span class="_ _c"> </span>Given<span class="_"> </span>the<span class="_"> </span>substantial<span class="_"> </span>architectural<span class="_"> </span>disparities<span class="_"> </span>and<span class="_"> </span>div<span class="_ _b"></span>erse<span class="_"> </span>choices<span class="_"> </span>of<span class="_"> </span>training<span class="_"> </span>datasets<span class="_ _a"> </span>for<span class="_"> </span>these<span class="_"> </span>multi-modal</div><div class="t m1f x6 h5 y110 ff1 fs2 fc0 sc0 ls0 ws0">models,<span class="_"> </span>curating<span class="_"> </span>compatible<span class="_"> </span>calibration<span class="_"> </span>datasets<span class="_"> </span>is<span class="_"> </span>deﬁnitely<span class="_"> </span>a<span class="_"> </span>maintenance<span class="_"> </span>headache.<span class="_ _c"> </span>Second,<span class="_"> </span>calibration-dependent</div><div class="t m20 x6 h5 y111 ff1 fs2 fc0 sc0 ls0 ws0">approaches<span class="_"> </span>tend<span class="_"> </span>to<span class="_"> </span>rely<span class="_"> </span>on<span class="_"> </span>GPUs<span class="_ _8"> </span>to<span class="_"> </span>perform<span class="_"> </span>the<span class="_"> </span>quantization<span class="_"> </span>as<span class="_"> </span>a<span class="_ _8"> </span>full<span class="_"> </span>inference<span class="_"> </span>pass<span class="_"> </span>is<span class="_"> </span>indispensable<span class="_"> </span>to<span class="_ _8"> </span>measure<span class="_"> </span>the</div><div class="t m2 x6 h5 y112 ff1 fs2 fc0 sc0 ls0 ws0">quantization<span class="_ _a"> </span>error<span class="_ _a"> </span>in<span class="_ _c"> </span>terms<span class="_ _a"> </span>of<span class="_ _a"> </span>activ<span class="_ _4"></span>ation.<span class="_ _f"> </span>This<span class="_"> </span>prevents<span class="_"> </span>ofﬂoading<span class="_"> </span>the<span class="_ _a"> </span>quantization<span class="_ _c"> </span>task<span class="_ _a"> </span>to<span class="_ _a"> </span>CPUs,<span class="_ _c"> </span>which<span class="_ _a"> </span>is<span class="_ _a"> </span>cheaper</div><div class="t m2 x6 h5 y113 ff1 fs2 fc0 sc0 ls0 ws0">and<span class="_"> </span>more<span class="_ _a"> </span>accessible.<span class="_ _10"> </span>Additionally<span class="_ _4"></span>,<span class="_ _a"> </span>the<span class="_ _a"> </span>quantization<span class="_ _a"> </span>speed<span class="_ _a"> </span>of<span class="_ _a"> </span>calibration<span class="_ _a"> </span>dataset-dependent<span class="_ _a"> </span>methods<span class="_"> </span>like<span class="_ _a"> </span>A<span class="_ _4"></span>WQ<span class="_"> </span>and</div><div class="t m4 x6 h5 y114 ff1 fs2 fc0 sc0 ls0 ws0">GPTQ<span class="_"> </span>is<span class="_"> </span>relativ<span class="_ _4"></span>ely<span class="_"> </span>slow<span class="_ _4"></span>.<span class="_ _c"> </span>For<span class="_"> </span>instance,<span class="_"> </span>the<span class="_"> </span>GPTQ<span class="_"> </span>method<span class="_"> </span>tak<span class="_ _b"></span>es<span class="_"> </span>approximately<span class="_"> </span>4<span class="_"> </span>GPU<span class="_"> </span>hours<span class="_"> </span>to<span class="_"> </span>quantize<span class="_"> </span>the<span class="_"> </span>OPT<span class="_ _1"></span>-175B</div><div class="t m2 x6 h5 y115 ff1 fs2 fc0 sc0 ls0 ws0">or<span class="_"> </span>BLOOM-176B<span class="_ _a"> </span>models<span class="_"> </span>[</div><div class="t m0 xc6 h5 y115 ff1 fs2 fc0 sc0 ls0 ws0">2</div><div class="t m2 xbf h5 y115 ff1 fs2 fc0 sc0 ls0 ws0">].<span class="_ _d"> </span>Finally<span class="_ _4"></span>,<span class="_ _a"> </span>the<span class="_"> </span>ﬁrst<span class="_ _a"> </span>four<span class="_ _a"> </span>quantization<span class="_"> </span>methods<span class="_ _a"> </span>surveyed<span class="_"> </span>in<span class="_"> </span>this<span class="_ _a"> </span>chapter<span class="_"> </span>employ<span class="_"> </span>uniform</div><div class="t m2 x6 h5 y116 ff1 fs2 fc0 sc0 ls0 ws0">quantization<span class="_"> </span>conﬁgurations<span class="_ _a"> </span>across<span class="_ _a"> </span>the<span class="_ _a"> </span>entire<span class="_ _a"> </span>model,<span class="_ _c"> </span>which<span class="_"> </span>may<span class="_ _a"> </span>be<span class="_ _a"> </span>sub-optimal<span class="_ _a"> </span>to<span class="_ _a"> </span>address<span class="_ _a"> </span>varying<span class="_"> </span>difﬁculty<span class="_"> </span>across</div><div class="t m0 x6 h5 y117 ff1 fs2 fc0 sc0 ls0 ws0">div<span class="_ _4"></span>erse<span class="_"> </span>layers<span class="_"> </span>of<span class="_"> </span>billion-scale<span class="_"> </span>LLMs.</div><div class="t m0 x6 h4 y118 ff2 fs3 fc0 sc0 ls0 ws0">3<span class="_ _e"> </span>Layer<span class="_ _4"></span>-sensitive<span class="_ _a"> </span>Quantization</div><div class="t m0 x6 h3 y119 ff2 fs2 fc0 sc0 ls0 ws0">3.1<span class="_ _14"> </span>Activation<span class="_ _8"> </span>Sensitivity</div><div class="t m2 x6 h5 y11a ff1 fs2 fc0 sc0 ls0 ws0">T<span class="_ _4"></span>ransformer-based<span class="_ _c"> </span>large<span class="_ _c"> </span>language<span class="_ _c"> </span>models<span class="_ _c"> </span>are<span class="_ _c"> </span>composed<span class="_ _d"> </span>of<span class="_ _c"> </span>multiple<span class="_ _c"> </span>layers<span class="_ _c"> </span>or<span class="_ _c"> </span>blocks<span class="_ _d"> </span>[</div><div class="t m0 xe8 h5 y11a ff1 fs2 fc0 sc0 ls0 ws0">27</div><div class="t m2 xe9 h5 y11a ff1 fs2 fc0 sc0 ls0 ws0">].<span class="_ _3"> </span>Each<span class="_ _c"> </span>layer<span class="_ _d"> </span>consists<span class="_ _c"> </span>of</div><div class="t m1d x6 h5 y11b ff1 fs2 fc0 sc0 ls0 ws0">the<span class="_"> </span>self-attention<span class="_"> </span>and<span class="_"> </span>Multi-Layer<span class="_ _8"> </span>Perceptron<span class="_"> </span>(MLP<span class="_ _15"></span>,<span class="_"> </span>a.k.a.<span class="_ _c"> </span>FFN)<span class="_"> </span>sub-layers.<span class="_ _c"> </span>Speciﬁcally<span class="_ _4"></span>,<span class="_"> </span>the<span class="_"> </span>Llama<span class="_ _8"> </span>family<span class="_"> </span>model’<span class="_ _4"></span>s</div><div class="t m2 x6 h5 y11c ff1 fs2 fc0 sc0 ls0 ws0">self-attention<span class="_ _d"> </span>includes<span class="_ _c"> </span>weights<span class="_ _d"> </span>for<span class="_ _d"> </span>K,<span class="_ _d"> </span>Q,<span class="_ _d"> </span>V<span class="_ _15"></span>,<span class="_ _c"> </span>and<span class="_ _d"> </span>O<span class="_ _d"> </span>projections,<span class="_ _d"> </span>known<span class="_ _d"> </span>as</div><div class="t m0 x9b h11 y11c ff5 fs2 fc0 sc0 ls0 ws0">k_proj</div><div class="t m2 xea h5 y11c ff1 fs2 fc0 sc0 ls0 ws0">,</div><div class="t m0 xd0 h11 y11c ff5 fs2 fc0 sc0 ls0 ws0">q_proj</div><div class="t m2 x75 h5 y11c ff1 fs2 fc0 sc0 ls0 ws0">,</div><div class="t m0 xeb h11 y11c ff5 fs2 fc0 sc0 ls0 ws0">v_proj</div><div class="t m2 xec h5 y11c ff1 fs2 fc0 sc0 ls0 ws0">,<span class="_ _d"> </span>and</div><div class="t m0 xed h11 y11c ff5 fs2 fc0 sc0 ls0 ws0">o_proj</div><div class="t m5 x6 h5 y11d ff1 fs2 fc0 sc0 ls0 ws0">respecti<span class="_ _b"></span>vely<span class="_ _1"></span>.<span class="_ _d"> </span>Similarly<span class="_ _4"></span>,<span class="_"> </span>the<span class="_"> </span>MLP<span class="_ _8"> </span>sub-layer<span class="_"> </span>is<span class="_"> </span>composed<span class="_"> </span>of<span class="_"> </span>wei<span class="_ _b"></span>ghts<span class="_"> </span>referred<span class="_"> </span>to<span class="_"> </span>as</div><div class="t m0 x8f h11 y11d ff5 fs2 fc0 sc0 ls0 ws0">mlp_proj</div><div class="t m5 x92 h5 y11d ff1 fs2 fc0 sc0 ls0 ws0">,</div><div class="t m0 x61 h11 y11d ff5 fs2 fc0 sc0 ls0 ws0">mlp_down</div><div class="t m5 xee h5 y11d ff1 fs2 fc0 sc0 ls0 ws0">,<span class="_"> </span>and</div><div class="t m0 xef h11 y11d ff5 fs2 fc0 sc0 ls0 ws0">mlp_gate</div><div class="t m5 xf0 h5 y11d ff1 fs2 fc0 sc0 ls0 ws0">.</div><div class="t m21 x6 h5 y11e ff1 fs2 fc0 sc0 ls0 ws0">The<span class="_"> </span>weights<span class="_"> </span>in<span class="_"> </span>a<span class="_"> </span>lar<span class="_ _b"></span>ge<span class="_"> </span>language<span class="_"> </span>model<span class="_"> </span>are<span class="_"> </span>not<span class="_"> </span>equally<span class="_"> </span>important<span class="_"> </span>as<span class="_"> </span>re<span class="_ _4"></span>vealed<span class="_"> </span>by<span class="_"> </span>the<span class="_"> </span>observ<span class="_ _b"></span>ation<span class="_"> </span>from<span class="_"> </span>prior<span class="_"> </span>study<span class="_"> </span>[</div><div class="t m0 x2d h5 y11e ff1 fs2 fc0 sc0 ls0 ws0">1</div><div class="t m21 x2e h5 y11e ff1 fs2 fc0 sc0 ls0 ws0">],</div><div class="t m2 x6 h5 y11f ff1 fs2 fc0 sc0 ls0 ws0">which<span class="_"> </span>claims<span class="_"> </span>that<span class="_"> </span>preserving<span class="_ _a"> </span>a<span class="_"> </span>small<span class="_"> </span>portion<span class="_"> </span>of<span class="_ _a"> </span>so-called<span class="_"> </span>salient<span class="_"> </span>weights<span class="_ _a"> </span>can<span class="_"> </span>signiﬁcantly<span class="_"> </span>improve<span class="_"> </span>the<span class="_"> </span>quantization</div><div class="t m7 x6 h5 y120 ff1 fs2 fc0 sc0 ls0 ws0">accuracy<span class="_ _1"></span>.<span class="_ _d"> </span>These<span class="_"> </span>weights<span class="_"> </span>correspond<span class="_"> </span>to<span class="_"> </span>particular<span class="_"> </span>channels<span class="_"> </span>inside<span class="_"> </span>a<span class="_"> </span>weight<span class="_"> </span>matrix.<span class="_ _d"> </span>Moti<span class="_ _4"></span>vated<span class="_"> </span>by<span class="_"> </span>this<span class="_"> </span>ﬁnding,<span class="_"> </span>this<span class="_"> </span>paper</div><div class="t m2 x6 h5 y121 ff1 fs2 fc0 sc0 ls0 ws0">hypothesizes<span class="_"> </span>that<span class="_"> </span>there<span class="_"> </span>also<span class="_"> </span>e<span class="_ _4"></span>xist<span class="_"> </span>sensitive<span class="_"> </span>layers<span class="_ _8"> </span>that<span class="_"> </span>are<span class="_"> </span>more<span class="_"> </span>se<span class="_ _4"></span>verely<span class="_"> </span>affected<span class="_ _8"> </span>by<span class="_"> </span>weight<span class="_"> </span>perturbation<span class="_"> </span>than<span class="_"> </span>others.</div><div class="t m0 x6 h5 y122 ff1 fs2 fc0 sc0 ls0 ws0">Protecting<span class="_"> </span>such<span class="_"> </span>layers<span class="_"> </span>by<span class="_"> </span>allocating<span class="_"> </span>a<span class="_"> </span>larger<span class="_"> </span>bit<span class="_"> </span>b<span class="_ _4"></span>udget<span class="_"> </span>will<span class="_"> </span>result<span class="_"> </span>in<span class="_"> </span>an<span class="_"> </span>improvement<span class="_"> </span>in<span class="_"> </span>o<span class="_ _b"></span>verall<span class="_"> </span>quantization<span class="_"> </span>accurac<span class="_ _b"></span>y<span class="_ _4"></span>.</div><div class="t m2 x6 h3 y123 ff2 fs2 fc0 sc0 ls0 ws0">Activation<span class="_ _a"> </span>Sensiti<span class="_ _b"></span>vity<span class="_ _a"> </span>Score<span class="_ _a"> </span><span class="ff1">In<span class="_"> </span>this<span class="_"> </span>section,<span class="_ _a"> </span>we<span class="_ _a"> </span>deﬁne<span class="_ _a"> </span>Activ<span class="_ _b"></span>ation<span class="_"> </span>Sensitivity<span class="_"> </span>Score,<span class="_ _a"> </span>formulated<span class="_ _a"> </span>in<span class="_ _a"> </span>Equation<span class="_ _a"> </span>10,<span class="_ _a"> </span>as</span></div><div class="t m3 x6 h5 y124 ff1 fs2 fc0 sc0 ls0 ws0">mean<span class="_"> </span>squared<span class="_"> </span>error<span class="_"> </span>between<span class="_"> </span>the<span class="_"> </span>acti<span class="_ _4"></span>vations<span class="_"> </span>obtained<span class="_"> </span>by<span class="_"> </span>multiplying<span class="_"> </span>the<span class="_"> </span>original<span class="_"> </span>and<span class="_"> </span>quantized<span class="_"> </span>weight<span class="_ _8"> </span>with<span class="_"> </span>the<span class="_"> </span>input.</div><div class="t m0 x6 h5 y125 ff1 fs2 fc0 sc0 ls0 ws0">This<span class="_"> </span>metric<span class="_"> </span>quantiﬁes<span class="_"> </span>layer-wise<span class="_"> </span>sensiti<span class="_ _4"></span>vity<span class="_"> </span>to<span class="_"> </span>perturbation<span class="_"> </span>introduced<span class="_"> </span>by<span class="_"> </span>quantization<span class="_"> </span>error<span class="_"> </span>of<span class="_"> </span>a<span class="_"> </span>particular<span class="_"> </span>model.</div><div class="t m0 xc1 h6 y126 ffb fs2 fc0 sc0 ls0 ws0">s</div><div class="t m0 x4b hd y127 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x95 h6 y126 ffd fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x97 hf y128 ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x97 hf y129 ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x97 hf y12a ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xf1 h6 y12b ffb fs2 fc0 sc0 ls0 ws0">W</div><div class="t m0 xf2 hd y12c ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x64 h6 y12b ff4 fs2 fc0 sc0 ls0 ws0">·<span class="_ _8"> </span><span class="ffb">X<span class="_ _c"> </span></span>−<span class="_ _8"> </span><span class="ffb">Q</span></div><div class="t m0 xb1 hc y12d ffc fs7 fc0 sc0 ls0 ws0">−<span class="fff">1</span></div><div class="t m0 x4f h6 y12b ffd fs2 fc0 sc0 ls0 ws0">(<span class="ffb">Q</span>(<span class="ffb">W</span></div><div class="t m0 xdd hd y12c ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x68 h6 y12b ffd fs2 fc0 sc0 ls0 ws0">))<span class="_ _8"> </span><span class="ff4">·<span class="_ _8"> </span><span class="ffb">X</span></span></div><div class="t m0 x5a hf y128 ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5a hf y129 ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5a hf y12a ff11 fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x9 hc y12e fff fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x9 hc y12f fff fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xf3 h6 y130 ff4 fs2 fc0 sc0 ls0 ws0">|<span class="ffb">W</span></div><div class="t m0 x42 hd y131 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xa3 h6 y130 ff4 fs2 fc0 sc0 ls0 ws0">·<span class="_ _8"> </span><span class="ffb">X<span class="_ _0"></span></span>|</div><div class="t m0 x54 h5 y126 ff1 fs2 fc0 sc0 ls0 ws0">(10)</div><div class="t m0 x38 h5 y48 ff1 fs2 fc0 sc0 ls0 ws0">5</div><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,417.527,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:203.072000px;bottom:1362.288000px;width:5.974000px;height:7.847000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",72,478.298,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:262.212000px;bottom:1297.032000px;width:10.955000px;height:7.747000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf5" data-dest-detail='[5,"XYZ",183.634,602.941,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:552.202000px;bottom:1292.718000px;width:5.974000px;height:9.904000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf5" data-dest-detail='[5,"XYZ",183.634,602.941,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:366.202000px;bottom:936.716000px;width:5.875000px;height:9.904000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",72,452.557,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:760.096000px;bottom:940.830000px;width:10.956000px;height:7.847000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",72,437.606,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:465.588000px;bottom:919.012000px;width:10.955000px;height:7.847000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",72,478.298,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:602.274000px;bottom:919.212000px;width:10.955000px;height:7.747000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,442.411,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:363.708000px;bottom:668.252000px;width:5.973000px;height:7.747000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",72,422.775,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:853.344000px;bottom:483.918000px;width:10.955000px;height:7.847000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",72,469.866,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:1057.768000px;bottom:396.846000px;width:5.974000px;height:7.747000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf5" data-dest-detail='[5,"XYZ",230.382,87.252,null]'><div class="d mf" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:1029.050000px;bottom:272.482000px;width:11.154000px;height:10.013000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[2.000000,0.000000,0.000000,2.000000,0.000000,0.000000]}'></div></div>
